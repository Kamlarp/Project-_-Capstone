{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Import Libraries -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import the vectorizers, scaler, smote\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# import the model including logistic regression, decision tree, bagged decision tree, random forest, ada boost, gradient boost, xgboost, svm \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import grid search cv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import make scorer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# import the metrics including accuracy score, precision score, recall score, f1 score, roc auc score, confusion matrix as well as classification report, roc curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Import Data -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the file \"df_pantip_posts_suicide_labeled_processed.csv\" from output folder\n",
    "df_pantip_posts_suicide_labeled_processed = pd.read_csv('../output - final/df_pantip_posts_suicide_labeled_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Define X,y and Do Train-test Split -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'index', 'title', 'url', 'label', 'tags', 'text',\n",
      "       'profile', 'time', 'sub_label', 'all_text', 'tokenized_text',\n",
      "       'day_week', 'day_month', 'month_year', 'year', 'time_day', 'title_len',\n",
      "       'text_len', 'title_emoji', 'text_emoji'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# list columns\n",
    "print(df_pantip_posts_suicide_labeled_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "index             0\n",
       "title             0\n",
       "url               0\n",
       "label             0\n",
       "tags              0\n",
       "text              0\n",
       "profile           0\n",
       "time              0\n",
       "sub_label         0\n",
       "all_text          0\n",
       "tokenized_text    0\n",
       "day_week          0\n",
       "day_month         0\n",
       "month_year        0\n",
       "year              0\n",
       "time_day          0\n",
       "title_len         0\n",
       "text_len          0\n",
       "title_emoji       0\n",
       "text_emoji        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NaN\n",
    "df_pantip_posts_suicide_labeled_processed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X: Index(['sub_label', 'tokenized_text', 'day_week', 'day_month', 'month_year',\n",
      "       'year', 'time_day', 'text_len', 'text_emoji'],\n",
      "      dtype='object')\n",
      "shape in X: (1261, 9)\n",
      "Columns in y: Index(['sub_label'], dtype='object')\n",
      "shape in y (1261, 1)\n",
      "sub_label\n",
      "11           779\n",
      "12           482\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to include only rows where 'sub_label' is 11 or 12\n",
    "filtered_df = df_pantip_posts_suicide_labeled_processed[df_pantip_posts_suicide_labeled_processed['sub_label'].isin([11, 12])]\n",
    "\n",
    "# Define 'X' to contain only the 'sub_label' column of the filtered DataFrame\n",
    "y = filtered_df[['sub_label']]\n",
    "\n",
    "# Define 'y' to include the specified columns of the filtered DataFrame\n",
    "X = filtered_df.drop(columns=['Unnamed: 0', 'tags', 'index', 'title', 'url', 'label', 'text','all_text',\n",
    "       'profile', 'time', 'title_len','title_emoji' ])\n",
    "\n",
    "# Print the columns of 'X' and 'y'\n",
    "print(\"Columns in X:\", X.columns)\n",
    "print('shape in X:', X.shape)\n",
    "print(\"Columns in y:\", y.columns)\n",
    "print('shape in y', y.shape)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24180\\3308730798.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['sub_label'] = y['sub_label'].map(mapping_value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sub_label\n",
       "1    779\n",
       "0    482\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform value in column 'sub_label'\n",
    "# 11 = 1\n",
    "# 12 = 0\n",
    "\n",
    "#create mapping value\n",
    "mapping_value = {11:1, 12:0}\n",
    "\n",
    "#map value on column 'sub_label'(\n",
    "y['sub_label'] = y['sub_label'].map(mapping_value)\n",
    "\n",
    "#show result \n",
    "y['sub_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42, stratify= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Feature Engineering -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day_week_Monday', 'day_week_Saturday', 'day_week_Sunday',\n",
      "       'day_week_Thursday', 'day_week_Tuesday', 'day_week_Wednesday',\n",
      "       'day_month_2', 'day_month_3', 'day_month_4', 'day_month_5',\n",
      "       'day_month_6', 'day_month_7', 'day_month_8', 'day_month_9',\n",
      "       'day_month_10', 'day_month_11', 'day_month_12', 'day_month_13',\n",
      "       'day_month_14', 'day_month_15', 'day_month_16', 'day_month_17',\n",
      "       'day_month_18', 'day_month_19', 'day_month_20', 'day_month_21',\n",
      "       'day_month_22', 'day_month_23', 'day_month_24', 'day_month_25',\n",
      "       'day_month_26', 'day_month_27', 'day_month_28', 'day_month_29',\n",
      "       'day_month_30', 'day_month_31', 'month_year_August',\n",
      "       'month_year_December', 'month_year_February', 'month_year_January',\n",
      "       'month_year_July', 'month_year_June', 'month_year_March',\n",
      "       'month_year_May', 'month_year_November', 'month_year_October',\n",
      "       'month_year_September', 'year_2017', 'year_2018', 'year_2019',\n",
      "       'year_2020', 'year_2021', 'year_2022', 'year_2023', 'time_day_12-15',\n",
      "       'time_day_15-18', 'time_day_18-21', 'time_day_21-24', 'time_day_3-6',\n",
      "       'time_day_6-9', 'time_day_9-12', 'text_emoji_1'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1008, 62)\n"
     ]
    }
   ],
   "source": [
    "#Step 1: One-Hot Encoding for Categorical Data\n",
    "\n",
    "cols = ['day_week', 'day_month', 'month_year', 'year', 'time_day','text_emoji']\n",
    "X_train_categorical = pd.get_dummies(X_train[cols], columns=cols, drop_first=True, dtype=int)\n",
    "X_test_categorical = pd.get_dummies(X_test[cols], columns=cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(X_train_categorical.columns)\n",
    "print(type(X_train_categorical))\n",
    "print(X_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(1008, 4678)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(253, 4678)\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Vectorization of 'tokenized_text'\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_text = vectorizer.fit_transform(X_train['tokenized_text'])\n",
    "X_test_text = vectorizer.transform(X_test['tokenized_text'])\n",
    "\n",
    "print(type(X_train_text))\n",
    "print(X_train_text.shape)\n",
    "\n",
    "print(type(X_test_text))\n",
    "print(X_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1008, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Scaling of Numerical Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_numerical = scaler.fit_transform(X_train[['text_len']])\n",
    "X_test_numerical = scaler.transform(X_test[['text_len']])\n",
    "\n",
    "print(type(X_train_numerical))\n",
    "X_train_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 4741)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Concatenate All Features for Training Data\n",
    "\n",
    "X_train_all = pd.concat([\n",
    "    pd.DataFrame(X_train_numerical, columns=['text_len'], index=X_train.index),\n",
    "    pd.DataFrame(X_train_text.todense(), columns=vectorizer.get_feature_names_out(), index=X_train.index),\n",
    "    X_train_categorical\n",
    "], axis=1)\n",
    "\n",
    "print(X_train_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 4741)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Concatenate All Features for Test Data\n",
    "X_test_all = pd.concat([\n",
    "    pd.DataFrame(X_test_numerical, columns=['text_len'], index=X_test.index),\n",
    "    pd.DataFrame(X_test_text.todense(), columns=vectorizer.get_feature_names_out(), index=X_test.index),\n",
    "    X_test_categorical\n",
    "], axis=1)\n",
    "\n",
    "print(X_test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1246, 4741)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: smote X_train and y_train\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train_all, y_train)\n",
    "\n",
    "print(X_train_sm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>__</th>\n",
       "      <th>_อ</th>\n",
       "      <th>admid</th>\n",
       "      <th>adobe</th>\n",
       "      <th>advice</th>\n",
       "      <th>alert</th>\n",
       "      <th>all</th>\n",
       "      <th>alone</th>\n",
       "      <th>amilykatze</th>\n",
       "      <th>...</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>time_day_12-15</th>\n",
       "      <th>time_day_15-18</th>\n",
       "      <th>time_day_18-21</th>\n",
       "      <th>time_day_21-24</th>\n",
       "      <th>time_day_3-6</th>\n",
       "      <th>time_day_6-9</th>\n",
       "      <th>time_day_9-12</th>\n",
       "      <th>text_emoji_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14461</th>\n",
       "      <td>0.285336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23799</th>\n",
       "      <td>-0.525559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23356</th>\n",
       "      <td>-0.373309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>0.177768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14118</th>\n",
       "      <td>-0.558657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>-0.594237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>0.392076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>-0.474257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>-0.403925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6029</th>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 4741 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_len   __   _อ  admid  adobe  advice  alert  all  alone  \\\n",
       "14461  0.285336  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "23799 -0.525559  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "23356 -0.373309  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "7864   0.177768  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "14118 -0.558657  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "...         ...  ...  ...    ...    ...     ...    ...  ...    ...   \n",
       "17989 -0.594237  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "15986  0.392076  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "8571  -0.474257  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "9171  -0.403925  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "6029   0.014762  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "\n",
       "       amilykatze  ...  year_2022  year_2023  time_day_12-15  time_day_15-18  \\\n",
       "14461         0.0  ...          0          0               0               0   \n",
       "23799         0.0  ...          0          1               0               0   \n",
       "23356         0.0  ...          0          1               0               0   \n",
       "7864          0.0  ...          0          0               0               0   \n",
       "14118         0.0  ...          0          0               1               0   \n",
       "...           ...  ...        ...        ...             ...             ...   \n",
       "17989         0.0  ...          0          0               0               0   \n",
       "15986         0.0  ...          0          0               0               0   \n",
       "8571          0.0  ...          0          0               0               0   \n",
       "9171          0.0  ...          0          0               0               0   \n",
       "6029          0.0  ...          0          0               0               1   \n",
       "\n",
       "       time_day_18-21  time_day_21-24  time_day_3-6  time_day_6-9  \\\n",
       "14461               0               0             0             0   \n",
       "23799               0               0             0             0   \n",
       "23356               1               0             0             0   \n",
       "7864                1               0             0             0   \n",
       "14118               0               0             0             0   \n",
       "...               ...             ...           ...           ...   \n",
       "17989               0               0             0             0   \n",
       "15986               1               0             0             0   \n",
       "8571                0               0             0             0   \n",
       "9171                1               0             0             0   \n",
       "6029                0               0             0             0   \n",
       "\n",
       "       time_day_9-12  text_emoji_1  \n",
       "14461              1             0  \n",
       "23799              1             0  \n",
       "23356              0             0  \n",
       "7864               0             0  \n",
       "14118              0             0  \n",
       "...              ...           ...  \n",
       "17989              1             0  \n",
       "15986              0             0  \n",
       "8571               0             0  \n",
       "9171               0             0  \n",
       "6029               0             0  \n",
       "\n",
       "[253 rows x 4741 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Checking and Renaming Duplicate Features\n",
    "\n",
    "# Function to rename duplicate columns by adding a suffix\n",
    "def rename_duplicates(df):\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values.tolist()] = [dup + '_' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "# Apply it to your training data\n",
    "rename_duplicates(X_train_sm)\n",
    "\n",
    "# If you're transforming your test data similarly, apply it there too\n",
    "rename_duplicates(X_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Do the simple modeling & evalutaing to test computing time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Run Logistic Regression Model to test compute time\n",
    "lr = LogisticRegression(random_state=42, class_weight={1:1, 0:1})\n",
    "lr.fit(X_train_sm, y_train_sm)\n",
    "y_pred_lr = lr.predict(X_test_all)\n",
    "y_pred_lr_proba = lr.predict_proba(X_test_all)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for Logistic Regression\n",
    "\n",
    "def get_pred_by_proba(proba, threshold=0.5):\n",
    "    return [1 if p >= threshold else 0 for p in proba]\n",
    "\n",
    "\n",
    "y_pred_lr = get_pred_by_proba(y_pred_lr_proba, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "ROC AUC score:  0.7517182130584195\n",
      "Confusion Matrix: \n",
      " [[ 65  32]\n",
      " [ 26 130]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69        97\n",
      "           1       0.80      0.83      0.82       156\n",
      "\n",
      "    accuracy                           0.77       253\n",
      "   macro avg       0.76      0.75      0.75       253\n",
      "weighted avg       0.77      0.77      0.77       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model both test and train model comparison for Logistic Regression\n",
    "print('Logistic Regression')\n",
    "print('ROC AUC score: ', roc_auc_score(y_test, y_pred_lr))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred_lr))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Decision Tree Model\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight={0:1, 1:3}, random_state=42)\n",
    "dt.fit(X_train_sm, y_train_sm)\n",
    "y_pred_dt = dt.predict(X_test_all)\n",
    "y_pred_dt_proba = dt.predict_proba(X_test_all)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold\n",
    "\n",
    "def get_pred_by_proba(proba, threshold=0.5):\n",
    "    return [1 if p >= threshold else 0 for p in proba]\n",
    "\n",
    "y_pred_dt = get_pred_by_proba(y_pred_dt_proba, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy score:  0.8023715415019763\n",
      "Precision score:  0.8486842105263158\n",
      "Recall score:  0.8269230769230769\n",
      "F1 score:  0.8376623376623378\n",
      "ROC AUC score:  0.7949048374306106\n",
      "Confusion Matrix: \n",
      " [[ 74  23]\n",
      " [ 27 129]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75        97\n",
      "           1       0.85      0.83      0.84       156\n",
      "\n",
      "    accuracy                           0.80       253\n",
      "   macro avg       0.79      0.79      0.79       253\n",
      "weighted avg       0.80      0.80      0.80       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model both test and train model comparison\n",
    "\n",
    "print('Decision Tree')\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_dt))\n",
    "print('Precision score: ', precision_score(y_test, y_pred_dt))\n",
    "print('Recall score: ', recall_score(y_test, y_pred_dt))\n",
    "print('F1 score: ', f1_score(y_test, y_pred_dt))\n",
    "print('ROC AUC score: ', roc_auc_score(y_test, y_pred_dt))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred_dt))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred_dt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
