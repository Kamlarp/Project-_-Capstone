{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Import Libraries -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast, json\n",
    "\n",
    "# import the libraries for importing the model \n",
    "import pickle\n",
    "\n",
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import the vectorizers, scaler, smote\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# import the model including logistic regression, decision tree, bagged decision tree, random forest, ada boost, gradient boost, xgboost, svm \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import the metrics including accuracy score, precision score, recall score, f1 score, roc auc score, confusion matrix as well as classification report, roc curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Import Model -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the file '../model/pantip_post_model_train_simplified_label_lr.pkl', so we can use the model to predict the new data\n",
    "with open('../model/pantip_post_model_train_simplified_sublabel_lr.pkl', 'rb') as file:\n",
    "    pantip_post_model_train_simplified_sublabel_lr = pickle.load(file)\n",
    "\n",
    "# import the file '../model/pantip_post_model_train_simplified_label_vectorizer.pkl', so we can use the vectorizer to transform the new data\n",
    "with open('../model/pantip_post_model_train_simplified_sublabel_vectorizer.pkl', 'rb') as file:\n",
    "    pantip_post_model_train_simplified_sublabel_vectorizer = pickle.load(file)\n",
    "\n",
    "# import the file '../model/pantip_post_model_train_simplified_label_scaler.pkl', so we can use the scaler to transform the new data\n",
    "with open('../model/pantip_post_model_train_simplified_sublabel_scaler.pkl', 'rb') as file:\n",
    "    pantip_post_model_train_simplified_sublabel_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Import Data -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data from '../output - final/df_youtube_comment_suicide_labeled_processed.csv', so we can use the model to predict the new data\n",
    "df_youtube_comment_suicide_labeled_processed = pd.read_csv('../output - final/df_youtube_comment_suicide_labeled_processed.csv')\n",
    "\n",
    "# import the data from '../model/X_train_sm_columns.json', so we can use the data in the dataframe to match the X_sm and use the model 'pantip_post_model_train_simplified_label_lr.pkl' to predict\n",
    "with open('../model/X_train_sm_sublabel_columns.json') as f:\n",
    "    X_train_sm_columns = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Define X,y -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13360, 15)\n",
      "Index(['Unnamed: 0', 'videoId', 'title', 'comment', 'date', 'label',\n",
      "       'sub_label', 'tokenized_text', 'day_week', 'day_month', 'month_year',\n",
      "       'year', 'time_day', 'text_len', 'text_emoji'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sub_label\n",
       "0     12883\n",
       "12      271\n",
       "11      206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the column of the dataframe df_youtube_comment_suicide_labeled_processed \n",
    "print(df_youtube_comment_suicide_labeled_processed.shape)\n",
    "print(df_youtube_comment_suicide_labeled_processed.columns)\n",
    "df_youtube_comment_suicide_labeled_processed['sub_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows where 'sub_label' is 11 or 12\n",
    "filtered_df = df_youtube_comment_suicide_labeled_processed[df_youtube_comment_suicide_labeled_processed['sub_label'].isin([11, 12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 8)\n",
      "(477,)\n",
      "12883    11\n",
      "12884    11\n",
      "12885    11\n",
      "12886    11\n",
      "12887    11\n",
      "Name: sub_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>day_week</th>\n",
       "      <th>day_month</th>\n",
       "      <th>month_year</th>\n",
       "      <th>year</th>\n",
       "      <th>time_day</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12883</th>\n",
       "      <td>['แม่', 'เหนื่อย', 'อารมณ์', 'แม่', 'คนใน', 'ค...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>30</td>\n",
       "      <td>October</td>\n",
       "      <td>2022</td>\n",
       "      <td>21-24</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12884</th>\n",
       "      <td>['ตาย', 'มาด', 'ตาย', 'เบื่อ', 'ครอบครัว', 'เบ...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>November</td>\n",
       "      <td>2023</td>\n",
       "      <td>18-21</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885</th>\n",
       "      <td>['วิธี', 'รักษา', 'จำเป็นต้อง', 'คุย', 'โทรศัพ...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15</td>\n",
       "      <td>June</td>\n",
       "      <td>2023</td>\n",
       "      <td>21-24</td>\n",
       "      <td>2151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12886</th>\n",
       "      <td>['อันดับ', 'กระเพาะ', 'ท้องอืด', 'อาหาร', 'เปล...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>February</td>\n",
       "      <td>2022</td>\n",
       "      <td>15-18</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12887</th>\n",
       "      <td>['ขอบคุณ', 'รับฟัง', 'ช่อง', 'คิดสั้น']</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>25</td>\n",
       "      <td>December</td>\n",
       "      <td>2022</td>\n",
       "      <td>9-12</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenized_text  day_week  day_month  \\\n",
       "12883  ['แม่', 'เหนื่อย', 'อารมณ์', 'แม่', 'คนใน', 'ค...    Sunday         30   \n",
       "12884  ['ตาย', 'มาด', 'ตาย', 'เบื่อ', 'ครอบครัว', 'เบ...  Thursday         16   \n",
       "12885  ['วิธี', 'รักษา', 'จำเป็นต้อง', 'คุย', 'โทรศัพ...  Thursday         15   \n",
       "12886  ['อันดับ', 'กระเพาะ', 'ท้องอืด', 'อาหาร', 'เปล...  Saturday          5   \n",
       "12887            ['ขอบคุณ', 'รับฟัง', 'ช่อง', 'คิดสั้น']    Sunday         25   \n",
       "\n",
       "      month_year  year time_day  text_len  text_emoji  \n",
       "12883    October  2022    21-24       187           0  \n",
       "12884   November  2023    18-21       109           0  \n",
       "12885       June  2023    21-24      2151           0  \n",
       "12886   February  2022    15-18       201           0  \n",
       "12887   December  2022     9-12        51           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X,y which include the following columns ['tokenized_text', 'day_week', 'day_month', 'month_year', 'year', 'time_day', 'text_len', 'text_emoji']\n",
    "\n",
    "X = filtered_df[['tokenized_text', 'day_week', 'day_month', 'month_year', 'year', 'time_day', 'text_len', 'text_emoji']]\n",
    "y = filtered_df['sub_label']\n",
    "\n",
    "# Check X,y\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y.head())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Feature Engineering -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day_week_Monday', 'day_week_Saturday', 'day_week_Sunday',\n",
      "       'day_week_Thursday', 'day_week_Tuesday', 'day_week_Wednesday',\n",
      "       'day_month_2', 'day_month_3', 'day_month_4', 'day_month_5',\n",
      "       'day_month_6', 'day_month_7', 'day_month_8', 'day_month_9',\n",
      "       'day_month_10', 'day_month_11', 'day_month_12', 'day_month_13',\n",
      "       'day_month_14', 'day_month_15', 'day_month_16', 'day_month_17',\n",
      "       'day_month_18', 'day_month_19', 'day_month_20', 'day_month_21',\n",
      "       'day_month_22', 'day_month_23', 'day_month_24', 'day_month_25',\n",
      "       'day_month_26', 'day_month_27', 'day_month_28', 'day_month_29',\n",
      "       'day_month_30', 'day_month_31', 'month_year_August',\n",
      "       'month_year_December', 'month_year_February', 'month_year_January',\n",
      "       'month_year_July', 'month_year_June', 'month_year_March',\n",
      "       'month_year_May', 'month_year_November', 'month_year_October',\n",
      "       'month_year_September', 'year_2022', 'year_2023', 'time_day_12-15',\n",
      "       'time_day_15-18', 'time_day_18-21', 'time_day_21-24', 'time_day_3-6',\n",
      "       'time_day_6-9', 'time_day_9-12', 'text_emoji_1'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(477, 57)\n"
     ]
    }
   ],
   "source": [
    "#Step 1: One-Hot Encoding for Categorical Data\n",
    "\n",
    "cols = ['day_week', 'day_month', 'month_year', 'year', 'time_day', 'text_emoji']\n",
    "X_categorical = pd.get_dummies(X[cols], columns=cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(X_categorical.columns)\n",
    "print(type(X_categorical))\n",
    "print(X_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(477, 4678)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: use the imported vectorizer to vecdtorize the data\n",
    "\n",
    "X_text = pantip_post_model_train_simplified_sublabel_vectorizer.transform(X['tokenized_text'])\n",
    "\n",
    "print(type(X_text))\n",
    "X_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(477, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: use the imported scaler to scaling the data\n",
    "\n",
    "X_numerical = pantip_post_model_train_simplified_sublabel_scaler.transform(X[['text_len']])\n",
    "\n",
    "print(type(X_numerical))\n",
    "X_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 4736)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Concatenate All Features for Training Data\n",
    "\n",
    "X_all = pd.concat([\n",
    "    pd.DataFrame(X_numerical, columns=['text_len'], index=X.index),\n",
    "    pd.DataFrame(X_text.todense(), columns=pantip_post_model_train_simplified_sublabel_vectorizer.get_feature_names_out(), index=X.index),\n",
    "    X_categorical\n",
    "], axis=1)\n",
    "\n",
    "print(X_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 4736)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Checking and Renaming Duplicate Features\n",
    "\n",
    "# Function to rename duplicate columns by adding a suffix\n",
    "def rename_duplicates(df):\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values.tolist()] = [dup + '_' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "# Apply it to your training data\n",
    "rename_duplicates(X_all)\n",
    "\n",
    "# check the shape of X_all\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 4736)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4742"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 6: match the X_all columns with X_train_sm_columns, \n",
    "# so we can use X_all to predict the new data, using the trained model 'pantip_post_model_train_simplified_label_lr.pkl'\n",
    "\n",
    "# check the shape of X_sm and X_train_sm_columns\n",
    "print(X_all.shape)\n",
    "len(X_train_sm_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 4742)\n"
     ]
    }
   ],
   "source": [
    "# match the X_all.columns with columns_names_list \n",
    "# because columns_names_list is the list of columns of X_train_sm_columns which is used to train the model 'pantip_post_model_train_simplified_label_lr.pkl'\n",
    "# column_names_list is the feature list of the trained model 'pantip_post_model_train_simplified_label_lr.pkl'\n",
    "# x_all number of columns should the same as column_names_list's length\n",
    "\n",
    "# 1. Adding missing columns from column_names_list to X_sm and imputing with 0\n",
    "for col in X_train_sm_columns:\n",
    "    if col not in X_all.columns:\n",
    "        X_all[col] = 0\n",
    "\n",
    "# 2. Dropping columns in X_sm that are not in column_names_list\n",
    "X_all = X_all[X_train_sm_columns]\n",
    "\n",
    "# This results in X_sm having the same columns as column_names_list, in the same order.\n",
    "# Missing columns are added and imputed with 0, and extra columns are dropped.\n",
    "\n",
    "# check the shape of X_all\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check whether all column names in X_sm are strings. If all are strings, it will return true\n",
    "print(X_all.columns.dtype == 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>__</th>\n",
       "      <th>_อ</th>\n",
       "      <th>admid</th>\n",
       "      <th>adobe</th>\n",
       "      <th>advice</th>\n",
       "      <th>alert</th>\n",
       "      <th>all</th>\n",
       "      <th>alone</th>\n",
       "      <th>amilykatze</th>\n",
       "      <th>...</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>time_day_12-15</th>\n",
       "      <th>time_day_15-18</th>\n",
       "      <th>time_day_18-21</th>\n",
       "      <th>time_day_21-24</th>\n",
       "      <th>time_day_3-6</th>\n",
       "      <th>time_day_6-9</th>\n",
       "      <th>time_day_9-12</th>\n",
       "      <th>title_emoji_1</th>\n",
       "      <th>text_emoji_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12883</th>\n",
       "      <td>-0.593409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12884</th>\n",
       "      <td>-0.657950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885</th>\n",
       "      <td>1.031690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12886</th>\n",
       "      <td>-0.581825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12887</th>\n",
       "      <td>-0.705942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>-0.647193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13356</th>\n",
       "      <td>-0.480049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13357</th>\n",
       "      <td>-0.504873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13358</th>\n",
       "      <td>-0.163139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13359</th>\n",
       "      <td>-0.665397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 4742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_len   __   _อ  admid  adobe  advice  alert  all  alone  \\\n",
       "12883 -0.593409  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "12884 -0.657950  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "12885  1.031690  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "12886 -0.581825  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "12887 -0.705942  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "...         ...  ...  ...    ...    ...     ...    ...  ...    ...   \n",
       "13355 -0.647193  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "13356 -0.480049  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "13357 -0.504873  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "13358 -0.163139  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "13359 -0.665397  0.0  0.0    0.0    0.0     0.0    0.0  0.0    0.0   \n",
       "\n",
       "       amilykatze  ...  year_2023  time_day_12-15  time_day_15-18  \\\n",
       "12883         0.0  ...          0               0               0   \n",
       "12884         0.0  ...          1               0               0   \n",
       "12885         0.0  ...          1               0               0   \n",
       "12886         0.0  ...          0               0               1   \n",
       "12887         0.0  ...          0               0               0   \n",
       "...           ...  ...        ...             ...             ...   \n",
       "13355         0.0  ...          0               0               0   \n",
       "13356         0.0  ...          0               0               0   \n",
       "13357         0.0  ...          0               1               0   \n",
       "13358         0.0  ...          1               0               0   \n",
       "13359         0.0  ...          1               0               0   \n",
       "\n",
       "       time_day_18-21  time_day_21-24  time_day_3-6  time_day_6-9  \\\n",
       "12883               0               1             0             0   \n",
       "12884               1               0             0             0   \n",
       "12885               0               1             0             0   \n",
       "12886               0               0             0             0   \n",
       "12887               0               0             0             0   \n",
       "...               ...             ...           ...           ...   \n",
       "13355               0               1             0             0   \n",
       "13356               0               1             0             0   \n",
       "13357               0               0             0             0   \n",
       "13358               0               1             0             0   \n",
       "13359               1               0             0             0   \n",
       "\n",
       "       time_day_9-12  title_emoji_1  text_emoji_1  \n",
       "12883              0              0             0  \n",
       "12884              0              0             0  \n",
       "12885              0              0             0  \n",
       "12886              0              0             0  \n",
       "12887              1              0             0  \n",
       "...              ...            ...           ...  \n",
       "13355              0              0             0  \n",
       "13356              0              0             0  \n",
       "13357              0              0             0  \n",
       "13358              0              0             0  \n",
       "13359              0              0             0  \n",
       "\n",
       "[477 rows x 4742 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check X_all data\n",
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12883    11\n",
       "12884    11\n",
       "12885    11\n",
       "12886    11\n",
       "12887    11\n",
       "Name: sub_label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_label\n",
       "0    271\n",
       "1    206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 7: transform y\n",
    "\n",
    "# transform value in column 'sub_label'\n",
    "# 11 = 1\n",
    "# 12 = 0\n",
    "\n",
    "#create mapping value\n",
    "mapping_value = {11:1, 12:0}\n",
    "\n",
    "#map value on column 'sub_label'\n",
    "y = y.map(mapping_value)\n",
    "\n",
    "#show result \n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **----- Use the trained model to test the data -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trained model to test the processed data X_sm and y_sm\n",
    "y_pred = pantip_post_model_train_simplified_sublabel_lr.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7651991614255765\n",
      "precision score:  0.7175925925925926\n",
      "recall score:  0.7524271844660194\n",
      "f1 score:  0.7345971563981043\n",
      "roc auc score:  0.763667466771755\n",
      "confusion matrix:  [[210  61]\n",
      " [ 51 155]]\n",
      "classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       271\n",
      "           1       0.72      0.75      0.73       206\n",
      "\n",
      "    accuracy                           0.77       477\n",
      "   macro avg       0.76      0.76      0.76       477\n",
      "weighted avg       0.77      0.77      0.77       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate the test model using the metrics including accuracy score, precision score, recall score, f1 score, roc auc score, confusion matrix as well as classification report, roc curve\n",
    "print('accuracy score: ', accuracy_score(y, y_pred))\n",
    "print('precision score: ', precision_score(y, y_pred))\n",
    "print('recall score: ', recall_score(y, y_pred))\n",
    "print('f1 score: ', f1_score(y, y_pred))\n",
    "print('roc auc score: ', roc_auc_score(y, y_pred))\n",
    "print('confusion matrix: ', confusion_matrix(y, y_pred))\n",
    "print('classification report: ', classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
